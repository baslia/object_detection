{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-30T08:57:47.845550Z",
     "start_time": "2024-01-30T08:57:47.842314Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import DetrImageProcessor, DetrForObjectDetection, DetrFeatureExtractor, DetrConfig\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torch.nn import Linear"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Load one image to test\n",
    "image = Image.open('RebarDSC/images/rebar_0_20MM.jpg')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-30T08:44:37.367364Z",
     "start_time": "2024-01-30T08:44:37.355719Z"
    }
   },
   "id": "e9d638d81d94caea",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Load pre-trained model and image processor\n",
    "pretrained_model = \"facebook/detr-resnet-50\"\n",
    "processor = DetrImageProcessor.from_pretrained(pretrained_model, revision=\"no_timm\")\n",
    "model = DetrForObjectDetection.from_pretrained(pretrained_model, revision=\"no_timm\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-30T08:53:28.695763Z",
     "start_time": "2024-01-30T08:53:27.944531Z"
    }
   },
   "id": "52685952899234c9",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "inputs = processor(images=image, return_tensors=\"pt\")\n",
    "outputs = model(**inputs)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-30T08:45:42.461573Z",
     "start_time": "2024-01-30T08:45:41.698109Z"
    }
   },
   "id": "aede9ccb5f625b14",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected teddy bear with confidence 0.839 at location [108.81, 113.71, 2645.52, 3104.0]\n"
     ]
    }
   ],
   "source": [
    "# convert outputs (bounding boxes and class logits) to COCO API\n",
    "# let's only keep detections with score > 0.5\n",
    "target_sizes = torch.tensor([image.size[::-1]])\n",
    "results = processor.post_process_object_detection(outputs, target_sizes=target_sizes, threshold=0.5)[0]\n",
    "\n",
    "for score, label, box in zip(results[\"scores\"], results[\"labels\"], results[\"boxes\"]):\n",
    "    box = [round(i, 2) for i in box.tolist()]\n",
    "    print(\n",
    "            f\"Detected {model.config.id2label[label.item()]} with confidence \"\n",
    "            f\"{round(score.item(), 3)} at location {box}\"\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-30T08:46:12.310914Z",
     "start_time": "2024-01-30T08:46:12.306551Z"
    }
   },
   "id": "9f6f4b59ae8d8dfd",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "\nDetrConvEncoder requires the timm library but it was not found in your environment. You can install it with pip:\n`pip install timm`. Please note that you may need to restart your runtime after installation.\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[17], line 11\u001B[0m\n\u001B[1;32m      3\u001B[0m feature_extractor \u001B[38;5;241m=\u001B[39m DetrFeatureExtractor\u001B[38;5;241m.\u001B[39mfrom_pretrained(\n\u001B[1;32m      4\u001B[0m     pretrained_model, \u001B[38;5;28mformat\u001B[39m\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcoco_panoptic\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m      5\u001B[0m )\n\u001B[1;32m      6\u001B[0m config \u001B[38;5;241m=\u001B[39m DetrConfig\u001B[38;5;241m.\u001B[39mfrom_pretrained(\n\u001B[1;32m      7\u001B[0m     pretrained_model,\n\u001B[1;32m      8\u001B[0m     num_labels\u001B[38;5;241m=\u001B[39mnum_labels\n\u001B[1;32m      9\u001B[0m )\n\u001B[0;32m---> 11\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mDetrForObjectDetection\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_pretrained\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpretrained_model\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     12\u001B[0m model\u001B[38;5;241m.\u001B[39mdetr\u001B[38;5;241m.\u001B[39mclass_labels_classifier \u001B[38;5;241m=\u001B[39m Linear(\n\u001B[1;32m     13\u001B[0m     in_features\u001B[38;5;241m=\u001B[39mmodel\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mhidden_size,\n\u001B[1;32m     14\u001B[0m     out_features\u001B[38;5;241m=\u001B[39mnum_labels \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m,  \u001B[38;5;66;03m# +1 for \"no object\" class\u001B[39;00m\n\u001B[1;32m     15\u001B[0m )\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/py311/lib/python3.11/site-packages/transformers/modeling_utils.py:3236\u001B[0m, in \u001B[0;36mPreTrainedModel.from_pretrained\u001B[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001B[0m\n\u001B[1;32m   3233\u001B[0m     config \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m_check_and_enable_flash_attn_2(config, torch_dtype\u001B[38;5;241m=\u001B[39mtorch_dtype, device_map\u001B[38;5;241m=\u001B[39mdevice_map)\n\u001B[1;32m   3235\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m ContextManagers(init_contexts):\n\u001B[0;32m-> 3236\u001B[0m     model \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mcls\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mmodel_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mmodel_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3238\u001B[0m \u001B[38;5;66;03m# make sure we use the model's config since the __init__ call might have copied it\u001B[39;00m\n\u001B[1;32m   3239\u001B[0m config \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mconfig\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/py311/lib/python3.11/site-packages/transformers/models/detr/modeling_detr.py:1476\u001B[0m, in \u001B[0;36mDetrForObjectDetection.__init__\u001B[0;34m(self, config)\u001B[0m\n\u001B[1;32m   1473\u001B[0m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m(config)\n\u001B[1;32m   1475\u001B[0m \u001B[38;5;66;03m# DETR encoder-decoder model\u001B[39;00m\n\u001B[0;32m-> 1476\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel \u001B[38;5;241m=\u001B[39m \u001B[43mDetrModel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1478\u001B[0m \u001B[38;5;66;03m# Object detection heads\u001B[39;00m\n\u001B[1;32m   1479\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclass_labels_classifier \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mLinear(\n\u001B[1;32m   1480\u001B[0m     config\u001B[38;5;241m.\u001B[39md_model, config\u001B[38;5;241m.\u001B[39mnum_labels \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m   1481\u001B[0m )  \u001B[38;5;66;03m# We add one for the \"no object\" class\u001B[39;00m\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/py311/lib/python3.11/site-packages/transformers/models/detr/modeling_detr.py:1308\u001B[0m, in \u001B[0;36mDetrModel.__init__\u001B[0;34m(self, config)\u001B[0m\n\u001B[1;32m   1305\u001B[0m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m(config)\n\u001B[1;32m   1307\u001B[0m \u001B[38;5;66;03m# Create backbone + positional encoding\u001B[39;00m\n\u001B[0;32m-> 1308\u001B[0m backbone \u001B[38;5;241m=\u001B[39m \u001B[43mDetrConvEncoder\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1309\u001B[0m object_queries \u001B[38;5;241m=\u001B[39m build_position_encoding(config)\n\u001B[1;32m   1310\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbackbone \u001B[38;5;241m=\u001B[39m DetrConvModel(backbone, object_queries)\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/py311/lib/python3.11/site-packages/transformers/models/detr/modeling_detr.py:346\u001B[0m, in \u001B[0;36mDetrConvEncoder.__init__\u001B[0;34m(self, config)\u001B[0m\n\u001B[1;32m    343\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig \u001B[38;5;241m=\u001B[39m config\n\u001B[1;32m    345\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m config\u001B[38;5;241m.\u001B[39muse_timm_backbone:\n\u001B[0;32m--> 346\u001B[0m     \u001B[43mrequires_backends\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtimm\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    347\u001B[0m     kwargs \u001B[38;5;241m=\u001B[39m {}\n\u001B[1;32m    348\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m config\u001B[38;5;241m.\u001B[39mdilation:\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/py311/lib/python3.11/site-packages/transformers/utils/import_utils.py:1247\u001B[0m, in \u001B[0;36mrequires_backends\u001B[0;34m(obj, backends)\u001B[0m\n\u001B[1;32m   1245\u001B[0m failed \u001B[38;5;241m=\u001B[39m [msg\u001B[38;5;241m.\u001B[39mformat(name) \u001B[38;5;28;01mfor\u001B[39;00m available, msg \u001B[38;5;129;01min\u001B[39;00m checks \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m available()]\n\u001B[1;32m   1246\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m failed:\n\u001B[0;32m-> 1247\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(failed))\n",
      "\u001B[0;31mImportError\u001B[0m: \nDetrConvEncoder requires the timm library but it was not found in your environment. You can install it with pip:\n`pip install timm`. Please note that you may need to restart your runtime after installation.\n"
     ]
    }
   ],
   "source": [
    "# The model needs finetunning to detect rebar\n",
    "num_labels = 1\n",
    "feature_extractor = DetrFeatureExtractor.from_pretrained(\n",
    "    pretrained_model, format=\"coco_panoptic\"\n",
    ")\n",
    "config = DetrConfig.from_pretrained(\n",
    "    pretrained_model,\n",
    "    num_labels=num_labels\n",
    ")\n",
    "\n",
    "model = DetrForObjectDetection.from_pretrained(pretrained_model)\n",
    "model.detr.class_labels_classifier = Linear(\n",
    "    in_features=model.config.hidden_size,\n",
    "    out_features=num_labels + 1,  # +1 for \"no object\" class\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-30T08:59:23.660785Z",
     "start_time": "2024-01-30T08:59:23.050222Z"
    }
   },
   "id": "47e5f54eaf625a56",
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "DetrConfig {\n  \"activation_dropout\": 0.0,\n  \"activation_function\": \"relu\",\n  \"architectures\": [\n    \"DetrForObjectDetection\"\n  ],\n  \"attention_dropout\": 0.0,\n  \"auxiliary_loss\": false,\n  \"backbone\": \"resnet50\",\n  \"backbone_config\": null,\n  \"bbox_cost\": 5,\n  \"bbox_loss_coefficient\": 5,\n  \"class_cost\": 1,\n  \"classifier_dropout\": 0.0,\n  \"d_model\": 256,\n  \"decoder_attention_heads\": 8,\n  \"decoder_ffn_dim\": 2048,\n  \"decoder_layerdrop\": 0.0,\n  \"decoder_layers\": 6,\n  \"dice_loss_coefficient\": 1,\n  \"dilation\": false,\n  \"dropout\": 0.1,\n  \"encoder_attention_heads\": 8,\n  \"encoder_ffn_dim\": 2048,\n  \"encoder_layerdrop\": 0.0,\n  \"encoder_layers\": 6,\n  \"eos_coefficient\": 0.1,\n  \"giou_cost\": 2,\n  \"giou_loss_coefficient\": 2,\n  \"init_std\": 0.02,\n  \"init_xavier_std\": 1.0,\n  \"is_encoder_decoder\": true,\n  \"mask_loss_coefficient\": 1,\n  \"max_position_embeddings\": 1024,\n  \"model_type\": \"detr\",\n  \"num_channels\": 3,\n  \"num_hidden_layers\": 6,\n  \"num_queries\": 100,\n  \"position_embedding_type\": \"sine\",\n  \"scale_embedding\": false,\n  \"transformers_version\": \"4.35.2\",\n  \"use_pretrained_backbone\": true,\n  \"use_timm_backbone\": true\n}"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-30T08:54:49.292634Z",
     "start_time": "2024-01-30T08:54:49.287349Z"
    }
   },
   "id": "26ce577fe9e94511",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "3408d49f4ed3ffc"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
