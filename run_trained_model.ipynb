{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Predicting the number of rebar in an image\n",
    "After training the model, we can use it to predict the number of rebar in an image."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "66004d2c19e117c4"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-30T17:44:40.046461Z",
     "start_time": "2024-01-30T17:44:40.042054Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import pytorch_lightning as pl\n",
    "import pandas as pd\n",
    "from transformers import DetrForObjectDetection, DetrFeatureExtractor\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Create the Data loader to train the model\n",
    "class CocoDetection(torchvision.datasets.CocoDetection):\n",
    "    def __init__(self, img_folder, feature_extractor, mode='train'):\n",
    "        assert mode in ['train', 'val', 'test'],  f'Unknown mode: {mode}'\n",
    "        ann_file = os.path.join(img_folder, f\"annotations/{mode}.json\")\n",
    "        super(CocoDetection, self).__init__(img_folder, ann_file)\n",
    "        self.feature_extractor = feature_extractor\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # read in PIL image and target in COCO format\n",
    "        img, target = super(CocoDetection, self).__getitem__(idx)\n",
    "        \n",
    "        # preprocess image and target (converting target to DETR format, resizing + normalization of both image and target)\n",
    "        image_id = self.ids[idx]\n",
    "        target = {'image_id': image_id, 'annotations': target}\n",
    "        encoding = self.feature_extractor(images=img, annotations=target, return_tensors=\"pt\")\n",
    "        pixel_values = encoding[\"pixel_values\"].squeeze() # remove batch dimension\n",
    "        target = encoding[\"labels\"][0] # remove batch dimension\n",
    "\n",
    "        return pixel_values, target\n",
    "\n",
    "\n",
    "# We define our model based on DETR\n",
    "class Detr(pl.LightningModule):\n",
    "\n",
    "     def __init__(self, lr=1e-4, lr_backbone=1e-5, weight_decay=1e-4, num_queries=500, num_labels=2, pretrained_model=\"facebook/detr-resnet-50\"):\n",
    "         super().__init__()\n",
    "         # replace COCO classification head with custom head\n",
    "         self.model = DetrForObjectDetection.from_pretrained(pretrained_model, \n",
    "                                                             num_labels=num_labels,\n",
    "                                                             num_queries=num_queries,\n",
    "                                                             ignore_mismatched_sizes=True)\n",
    "         self.lr = lr\n",
    "         self.lr_backbone = lr_backbone\n",
    "         self.weight_decay = weight_decay\n",
    "\n",
    "     def forward(self, pixel_values, pixel_mask):\n",
    "       outputs = self.model(pixel_values=pixel_values, pixel_mask=pixel_mask)\n",
    "\n",
    "       return outputs\n",
    "     \n",
    "     def common_step(self, batch, batch_idx):\n",
    "       pixel_values = batch[\"pixel_values\"]\n",
    "       pixel_mask = batch[\"pixel_mask\"]\n",
    "       labels = [{k: v.to(self.device) for k, v in t.items()} for t in batch[\"labels\"]]\n",
    "\n",
    "       outputs = self.model(pixel_values=pixel_values, pixel_mask=pixel_mask, labels=labels)\n",
    "\n",
    "       loss = outputs.loss\n",
    "       loss_dict = outputs.loss_dict\n",
    "\n",
    "       return loss, loss_dict\n",
    "\n",
    "     def training_step(self, batch, batch_idx):\n",
    "        loss, loss_dict = self.common_step(batch, batch_idx)     \n",
    "        # logs metrics for each training_step,\n",
    "        # and the average across the epoch\n",
    "        self.log(\"training_loss\", loss)\n",
    "        for k,v in loss_dict.items():\n",
    "          self.log(\"train_\" + k, v.item())\n",
    "\n",
    "        return loss\n",
    "\n",
    "     def validation_step(self, batch, batch_idx):\n",
    "        loss, loss_dict = self.common_step(batch, batch_idx)     \n",
    "        self.log(\"validation_loss\", loss)\n",
    "        for k,v in loss_dict.items():\n",
    "          self.log(\"validation_\" + k, v.item())\n",
    "\n",
    "        return loss\n",
    "\n",
    "     def configure_optimizers(self):\n",
    "        param_dicts = [\n",
    "              {\"params\": [p for n, p in self.named_parameters() if \"backbone\" not in n and p.requires_grad]},\n",
    "              {\n",
    "                  \"params\": [p for n, p in self.named_parameters() if \"backbone\" in n and p.requires_grad],\n",
    "                  \"lr\": self.lr_backbone,\n",
    "              },\n",
    "        ]\n",
    "        optimizer = torch.optim.AdamW(param_dicts, lr=self.lr,\n",
    "                                  weight_decay=self.weight_decay)\n",
    "        \n",
    "        return optimizer\n",
    "     # \n",
    "     # def train_dataloader(self):\n",
    "     #    return train_dataloader\n",
    "     # \n",
    "     # def val_dataloader(self):\n",
    "     #    return val_dataloader"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-30T17:43:44.595030Z",
     "start_time": "2024-01-30T17:43:44.586459Z"
    }
   },
   "id": "bff45896c97f9fb7",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/detr-resnet-50 were not used when initializing DetrForObjectDetection: ['model.backbone.conv_encoder.model.layer1.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked']\n",
      "- This IS expected if you are initializing DetrForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DetrForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DetrForObjectDetection were not initialized from the model checkpoint at facebook/detr-resnet-50 and are newly initialized because the shapes did not match:\n",
      "- model.query_position_embeddings.weight: found shape torch.Size([100, 256]) in the checkpoint and torch.Size([500, 256]) in the model instantiated\n",
      "- class_labels_classifier.weight: found shape torch.Size([92, 256]) in the checkpoint and torch.Size([3, 256]) in the model instantiated\n",
      "- class_labels_classifier.bias: found shape torch.Size([92]) in the checkpoint and torch.Size([3]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": "Detr(\n  (model): DetrForObjectDetection(\n    (model): DetrModel(\n      (backbone): DetrConvModel(\n        (conv_encoder): DetrConvEncoder(\n          (model): FeatureListNet(\n            (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n            (bn1): DetrFrozenBatchNorm2d()\n            (act1): ReLU(inplace=True)\n            (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n            (layer1): Sequential(\n              (0): Bottleneck(\n                (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                (bn1): DetrFrozenBatchNorm2d()\n                (act1): ReLU(inplace=True)\n                (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n                (bn2): DetrFrozenBatchNorm2d()\n                (drop_block): Identity()\n                (act2): ReLU(inplace=True)\n                (aa): Identity()\n                (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                (bn3): DetrFrozenBatchNorm2d()\n                (act3): ReLU(inplace=True)\n                (downsample): Sequential(\n                  (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                  (1): DetrFrozenBatchNorm2d()\n                )\n              )\n              (1): Bottleneck(\n                (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                (bn1): DetrFrozenBatchNorm2d()\n                (act1): ReLU(inplace=True)\n                (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n                (bn2): DetrFrozenBatchNorm2d()\n                (drop_block): Identity()\n                (act2): ReLU(inplace=True)\n                (aa): Identity()\n                (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                (bn3): DetrFrozenBatchNorm2d()\n                (act3): ReLU(inplace=True)\n              )\n              (2): Bottleneck(\n                (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                (bn1): DetrFrozenBatchNorm2d()\n                (act1): ReLU(inplace=True)\n                (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n                (bn2): DetrFrozenBatchNorm2d()\n                (drop_block): Identity()\n                (act2): ReLU(inplace=True)\n                (aa): Identity()\n                (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                (bn3): DetrFrozenBatchNorm2d()\n                (act3): ReLU(inplace=True)\n              )\n            )\n            (layer2): Sequential(\n              (0): Bottleneck(\n                (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                (bn1): DetrFrozenBatchNorm2d()\n                (act1): ReLU(inplace=True)\n                (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n                (bn2): DetrFrozenBatchNorm2d()\n                (drop_block): Identity()\n                (act2): ReLU(inplace=True)\n                (aa): Identity()\n                (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                (bn3): DetrFrozenBatchNorm2d()\n                (act3): ReLU(inplace=True)\n                (downsample): Sequential(\n                  (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n                  (1): DetrFrozenBatchNorm2d()\n                )\n              )\n              (1): Bottleneck(\n                (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                (bn1): DetrFrozenBatchNorm2d()\n                (act1): ReLU(inplace=True)\n                (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n                (bn2): DetrFrozenBatchNorm2d()\n                (drop_block): Identity()\n                (act2): ReLU(inplace=True)\n                (aa): Identity()\n                (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                (bn3): DetrFrozenBatchNorm2d()\n                (act3): ReLU(inplace=True)\n              )\n              (2): Bottleneck(\n                (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                (bn1): DetrFrozenBatchNorm2d()\n                (act1): ReLU(inplace=True)\n                (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n                (bn2): DetrFrozenBatchNorm2d()\n                (drop_block): Identity()\n                (act2): ReLU(inplace=True)\n                (aa): Identity()\n                (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                (bn3): DetrFrozenBatchNorm2d()\n                (act3): ReLU(inplace=True)\n              )\n              (3): Bottleneck(\n                (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                (bn1): DetrFrozenBatchNorm2d()\n                (act1): ReLU(inplace=True)\n                (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n                (bn2): DetrFrozenBatchNorm2d()\n                (drop_block): Identity()\n                (act2): ReLU(inplace=True)\n                (aa): Identity()\n                (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                (bn3): DetrFrozenBatchNorm2d()\n                (act3): ReLU(inplace=True)\n              )\n            )\n            (layer3): Sequential(\n              (0): Bottleneck(\n                (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                (bn1): DetrFrozenBatchNorm2d()\n                (act1): ReLU(inplace=True)\n                (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n                (bn2): DetrFrozenBatchNorm2d()\n                (drop_block): Identity()\n                (act2): ReLU(inplace=True)\n                (aa): Identity()\n                (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                (bn3): DetrFrozenBatchNorm2d()\n                (act3): ReLU(inplace=True)\n                (downsample): Sequential(\n                  (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n                  (1): DetrFrozenBatchNorm2d()\n                )\n              )\n              (1): Bottleneck(\n                (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                (bn1): DetrFrozenBatchNorm2d()\n                (act1): ReLU(inplace=True)\n                (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n                (bn2): DetrFrozenBatchNorm2d()\n                (drop_block): Identity()\n                (act2): ReLU(inplace=True)\n                (aa): Identity()\n                (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                (bn3): DetrFrozenBatchNorm2d()\n                (act3): ReLU(inplace=True)\n              )\n              (2): Bottleneck(\n                (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                (bn1): DetrFrozenBatchNorm2d()\n                (act1): ReLU(inplace=True)\n                (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n                (bn2): DetrFrozenBatchNorm2d()\n                (drop_block): Identity()\n                (act2): ReLU(inplace=True)\n                (aa): Identity()\n                (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                (bn3): DetrFrozenBatchNorm2d()\n                (act3): ReLU(inplace=True)\n              )\n              (3): Bottleneck(\n                (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                (bn1): DetrFrozenBatchNorm2d()\n                (act1): ReLU(inplace=True)\n                (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n                (bn2): DetrFrozenBatchNorm2d()\n                (drop_block): Identity()\n                (act2): ReLU(inplace=True)\n                (aa): Identity()\n                (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                (bn3): DetrFrozenBatchNorm2d()\n                (act3): ReLU(inplace=True)\n              )\n              (4): Bottleneck(\n                (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                (bn1): DetrFrozenBatchNorm2d()\n                (act1): ReLU(inplace=True)\n                (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n                (bn2): DetrFrozenBatchNorm2d()\n                (drop_block): Identity()\n                (act2): ReLU(inplace=True)\n                (aa): Identity()\n                (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                (bn3): DetrFrozenBatchNorm2d()\n                (act3): ReLU(inplace=True)\n              )\n              (5): Bottleneck(\n                (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                (bn1): DetrFrozenBatchNorm2d()\n                (act1): ReLU(inplace=True)\n                (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n                (bn2): DetrFrozenBatchNorm2d()\n                (drop_block): Identity()\n                (act2): ReLU(inplace=True)\n                (aa): Identity()\n                (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                (bn3): DetrFrozenBatchNorm2d()\n                (act3): ReLU(inplace=True)\n              )\n            )\n            (layer4): Sequential(\n              (0): Bottleneck(\n                (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                (bn1): DetrFrozenBatchNorm2d()\n                (act1): ReLU(inplace=True)\n                (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n                (bn2): DetrFrozenBatchNorm2d()\n                (drop_block): Identity()\n                (act2): ReLU(inplace=True)\n                (aa): Identity()\n                (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                (bn3): DetrFrozenBatchNorm2d()\n                (act3): ReLU(inplace=True)\n                (downsample): Sequential(\n                  (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n                  (1): DetrFrozenBatchNorm2d()\n                )\n              )\n              (1): Bottleneck(\n                (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                (bn1): DetrFrozenBatchNorm2d()\n                (act1): ReLU(inplace=True)\n                (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n                (bn2): DetrFrozenBatchNorm2d()\n                (drop_block): Identity()\n                (act2): ReLU(inplace=True)\n                (aa): Identity()\n                (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                (bn3): DetrFrozenBatchNorm2d()\n                (act3): ReLU(inplace=True)\n              )\n              (2): Bottleneck(\n                (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                (bn1): DetrFrozenBatchNorm2d()\n                (act1): ReLU(inplace=True)\n                (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n                (bn2): DetrFrozenBatchNorm2d()\n                (drop_block): Identity()\n                (act2): ReLU(inplace=True)\n                (aa): Identity()\n                (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                (bn3): DetrFrozenBatchNorm2d()\n                (act3): ReLU(inplace=True)\n              )\n            )\n          )\n        )\n        (position_embedding): DetrSinePositionEmbedding()\n      )\n      (input_projection): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n      (query_position_embeddings): Embedding(500, 256)\n      (encoder): DetrEncoder(\n        (layers): ModuleList(\n          (0-5): 6 x DetrEncoderLayer(\n            (self_attn): DetrAttention(\n              (k_proj): Linear(in_features=256, out_features=256, bias=True)\n              (v_proj): Linear(in_features=256, out_features=256, bias=True)\n              (q_proj): Linear(in_features=256, out_features=256, bias=True)\n              (out_proj): Linear(in_features=256, out_features=256, bias=True)\n            )\n            (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n            (activation_fn): ReLU()\n            (fc1): Linear(in_features=256, out_features=2048, bias=True)\n            (fc2): Linear(in_features=2048, out_features=256, bias=True)\n            (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n          )\n        )\n      )\n      (decoder): DetrDecoder(\n        (layers): ModuleList(\n          (0-5): 6 x DetrDecoderLayer(\n            (self_attn): DetrAttention(\n              (k_proj): Linear(in_features=256, out_features=256, bias=True)\n              (v_proj): Linear(in_features=256, out_features=256, bias=True)\n              (q_proj): Linear(in_features=256, out_features=256, bias=True)\n              (out_proj): Linear(in_features=256, out_features=256, bias=True)\n            )\n            (activation_fn): ReLU()\n            (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n            (encoder_attn): DetrAttention(\n              (k_proj): Linear(in_features=256, out_features=256, bias=True)\n              (v_proj): Linear(in_features=256, out_features=256, bias=True)\n              (q_proj): Linear(in_features=256, out_features=256, bias=True)\n              (out_proj): Linear(in_features=256, out_features=256, bias=True)\n            )\n            (encoder_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n            (fc1): Linear(in_features=256, out_features=2048, bias=True)\n            (fc2): Linear(in_features=2048, out_features=256, bias=True)\n            (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n          )\n        )\n        (layernorm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n      )\n    )\n    (class_labels_classifier): Linear(in_features=256, out_features=3, bias=True)\n    (bbox_predictor): DetrMLPPredictionHead(\n      (layers): ModuleList(\n        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)\n        (2): Linear(in_features=256, out_features=4, bias=True)\n      )\n    )\n  )\n)"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up the device\n",
    "model1 = Detr\n",
    "model = Detr.load_from_checkpoint(\"./model/detr.ckpt\")\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "# Read the model from file\n",
    "model.to(device)\n",
    "model.eval()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-30T17:43:56.350673Z",
     "start_time": "2024-01-30T17:43:54.622941Z"
    }
   },
   "id": "8b12db8bbfac6708",
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.54s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "# Set up pre-trained model\n",
    "pretrained_model = \"facebook/detr-resnet-50\"\n",
    "img_folder = \"RebarDSC/images\"\n",
    "\n",
    "feature_extractor = DetrFeatureExtractor.from_pretrained(pretrained_model)\n",
    "\n",
    "test_dataset = CocoDetection(img_folder=f'{img_folder}', feature_extractor=feature_extractor, mode='test')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-30T17:44:49.708045Z",
     "start_time": "2024-01-30T17:44:49.005465Z"
    }
   },
   "id": "60148e0e1f5caa69",
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def count_rebar(outputs, threshold=0.7):\n",
    "  # keep only predictions with confidence >= threshold\n",
    "    probas = outputs.logits.softmax(-1)[0, :, :-1]\n",
    "    keep = probas.max(-1).values > threshold\n",
    "\n",
    "  # return the count of rebar\n",
    "    return len(probas[keep])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-30T17:44:53.774973Z",
     "start_time": "2024-01-30T17:44:53.771390Z"
    }
   },
   "id": "ee1e9be218cae5e5",
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "     image_id  count\n0           1    245\n1           3     46\n2           5    232\n3           9    199\n4          16    272\n..        ...    ...\n995      2117    149\n996      2118    280\n997      2121    174\n998      2123    266\n999      2124    198\n\n[1000 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_id</th>\n      <th>count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>245</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3</td>\n      <td>46</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5</td>\n      <td>232</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9</td>\n      <td>199</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>16</td>\n      <td>272</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>995</th>\n      <td>2117</td>\n      <td>149</td>\n    </tr>\n    <tr>\n      <th>996</th>\n      <td>2118</td>\n      <td>280</td>\n    </tr>\n    <tr>\n      <th>997</th>\n      <td>2121</td>\n      <td>174</td>\n    </tr>\n    <tr>\n      <th>998</th>\n      <td>2123</td>\n      <td>266</td>\n    </tr>\n    <tr>\n      <th>999</th>\n      <td>2124</td>\n      <td>198</td>\n    </tr>\n  </tbody>\n</table>\n<p>1000 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get count from the CSV file\n",
    "# res = pd.read_csv(\"RebarDSC/images/annotations/test.csv\", header=None)\n",
    "# res.columns = [\"image_name\", \"bbox\"]\n",
    "# res[\"image_id\"] = res[\"image_name\"].apply(lambda x: int(x.split(\"_\")[1]))\n",
    "# # Get the count of rebar per image_id\n",
    "# res = res.groupby(\"image_id\").count().reset_index()\n",
    "# res = res[[\"image_id\", \"bbox\"]]\n",
    "# res.columns = [\"image_id\", \"count\"]\n",
    "# res"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-30T17:44:56.522895Z",
     "start_time": "2024-01-30T17:44:56.363622Z"
    }
   },
   "id": "63074e5efcf879a6",
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/1000\n",
      "20/1000\n",
      "40/1000\n",
      "60/1000\n",
      "80/1000\n",
      "100/1000\n",
      "120/1000\n",
      "140/1000\n",
      "160/1000\n",
      "180/1000\n",
      "200/1000\n",
      "220/1000\n",
      "240/1000\n",
      "260/1000\n",
      "280/1000\n",
      "300/1000\n",
      "320/1000\n",
      "340/1000\n",
      "360/1000\n",
      "380/1000\n",
      "400/1000\n",
      "420/1000\n",
      "440/1000\n",
      "460/1000\n",
      "480/1000\n",
      "500/1000\n",
      "520/1000\n",
      "540/1000\n",
      "560/1000\n",
      "580/1000\n",
      "600/1000\n",
      "620/1000\n",
      "640/1000\n",
      "660/1000\n",
      "680/1000\n",
      "700/1000\n",
      "720/1000\n",
      "740/1000\n",
      "760/1000\n",
      "780/1000\n",
      "800/1000\n",
      "820/1000\n",
      "840/1000\n",
      "860/1000\n",
      "880/1000\n",
      "900/1000\n",
      "920/1000\n",
      "940/1000\n",
      "960/1000\n",
      "980/1000\n"
     ]
    },
    {
     "data": {
      "text/plain": "     image_id  pred_count  act_count\n0           1         475        245\n1           3           0         46\n2           5         343        232\n3           9         247        199\n4          16         499        272\n..        ...         ...        ...\n995      2117           0        149\n996      2118         496        280\n997      2121         491        174\n998      2123         402        266\n999      2124         136        198\n\n[1000 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_id</th>\n      <th>pred_count</th>\n      <th>act_count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>475</td>\n      <td>245</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3</td>\n      <td>0</td>\n      <td>46</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5</td>\n      <td>343</td>\n      <td>232</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9</td>\n      <td>247</td>\n      <td>199</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>16</td>\n      <td>499</td>\n      <td>272</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>995</th>\n      <td>2117</td>\n      <td>0</td>\n      <td>149</td>\n    </tr>\n    <tr>\n      <th>996</th>\n      <td>2118</td>\n      <td>496</td>\n      <td>280</td>\n    </tr>\n    <tr>\n      <th>997</th>\n      <td>2121</td>\n      <td>491</td>\n      <td>174</td>\n    </tr>\n    <tr>\n      <th>998</th>\n      <td>2123</td>\n      <td>402</td>\n      <td>266</td>\n    </tr>\n    <tr>\n      <th>999</th>\n      <td>2124</td>\n      <td>136</td>\n      <td>198</td>\n    </tr>\n  </tbody>\n</table>\n<p>1000 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the predictions\n",
    "pred_res = pd.DataFrame(columns=[\"image_id\", \"pred_count\", \"act_count\"])\n",
    "for it in iter(range(len(test_dataset))):\n",
    "    if it % 20 == 0:\n",
    "        print(f'{it}/{len(test_dataset)}')\n",
    "# it = iter(range(len(test_dataset)))\n",
    "    pixel_values, target = test_dataset[it]\n",
    "    act_count = target['class_labels'].sum().tolist()\n",
    "    \n",
    "    pixel_values = pixel_values.unsqueeze(0).to(device)\n",
    "    # print(pixel_values.shape)\n",
    "    outputs = model(pixel_values=pixel_values, pixel_mask=None)\n",
    "    image_id = target['image_id'].item()\n",
    "    # image = test_dataset.coco.loadImgs(image_id)[0]\n",
    "    pred_count = count_rebar(outputs, threshold=0.6)\n",
    "    \n",
    "    pred_res.loc[len(pred_res)] = [image_id, pred_count, act_count]\n",
    "    \n",
    "pred_res"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-30T18:25:24.865848Z",
     "start_time": "2024-01-30T18:20:37.344333Z"
    }
   },
   "id": "8f8de3649211db14",
   "execution_count": 60
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([500, 2])"
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# processor = DetrFeatureExtractor.from_pretrained(model)\n",
    "pixel_values, target = test_dataset[10]\n",
    "pixel_values = pixel_values.unsqueeze(0).to(device)\n",
    "outputs = model(pixel_values=pixel_values, pixel_mask=None)\n",
    "\n",
    "# print(outputs.logits)\n",
    "probas = outputs.logits.softmax(-1)[0, :, :-1]\n",
    "probas\n",
    "keep = probas.max(-1).values > 0.6\n",
    "\n",
    "  # return the count of rebar\n",
    "# len(probas[keep])\n",
    "# pixel_values\n",
    "# it\n",
    "probas.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-30T18:20:26.507383Z",
     "start_time": "2024-01-30T18:20:25.668636Z"
    }
   },
   "id": "ef431e3c94922957",
   "execution_count": 59
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[54], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mpred_res\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mact_count\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43miloc\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtolist\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\n",
      "\u001B[0;31mTypeError\u001B[0m: 'int' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "pred_res[\"act_count\"].iloc[0].tolist()[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-30T18:17:43.076991Z",
     "start_time": "2024-01-30T18:17:43.072131Z"
    }
   },
   "id": "7a735302e93211af",
   "execution_count": 54
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Merge the predictions with the ground truth\n",
    "# res = res.merge(pred_res, on=\"image_id\")\n",
    "# res"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c75d9b7b72e038fd"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 29205.638\n"
     ]
    }
   ],
   "source": [
    "# Get the MSE (Mean Squared Error)\n",
    "print(\"MSE:\", mean_squared_error(pred_res[\"act_count\"], pred_res[\"pred_count\"]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-30T18:26:12.384903Z",
     "start_time": "2024-01-30T18:26:12.380146Z"
    }
   },
   "id": "643e58b643a10f9",
   "execution_count": 61
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE naive: 6179.065775\n"
     ]
    }
   ],
   "source": [
    "# Compare the MSE to a naive model\n",
    "avg_count = pred_res[\"act_count\"].mean()\n",
    "print(\"MSE naive:\", mean_squared_error(pred_res[\"act_count\"], [avg_count]*len(pred_res)))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-30T18:26:27.890483Z",
     "start_time": "2024-01-30T18:26:27.884475Z"
    }
   },
   "id": "cf174a9830ad5277",
   "execution_count": 63
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "7d31561c31aa1967"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
